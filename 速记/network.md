1. TCP/IP四层模型

- 数据链路层：对应osi的物理层和数据链路层，通过物理手段将通信主机连接到网络中，将比特流数据分组为帧数据

- 网络层：对应osi的网络层，主机间通信，通过IP协议处理路由分组交换

- 传输层：对应osi的传输层和会话层，端到端通信，指定传输协议进行进程间的数据传输

- 应用层：对应osi的应用层和表示层，通过应用层协议对数据格式进行解析与发送

2. TCP报文段：TCP首部 + 数据部分组成，首部包括：seq序列号、ack确认号、ctl控制位和窗口字段等

- seq：发送数据在整个tcp连接中的序号，一开始通过随机算法初始化值，防止复用旧连接后导致数据错乱

- ack：接收方的确认号，也表示期望收到对方下一个报文段的字节序号

- ctl：

    - SYN：建立连接使用，出现在第一、二次握手

    - FIN：断开连接使用，出现在第一、三次挥手

    - ACK：有求必应，对发送分数据的确认响应，运用于TCP重传、校验机制

- checksum：校验和，接收方接收数据后计算校验和，不一致说明数据传输有误

3. 三次握手

- 连接建立发起方向接收方发送第一次握手SYN报文，连接方状态变为SYN_SEND，报文包含了seq初始值

- 接收方响应第二次握手SYN+ACK报文段，报文包含接收方的seq初始值与ack值，ack值为seq+1，随后接收方状态变为SYN_RCVD

- 发起方接收到第二次握手后状态进入ESTABLISHED，再返回给被连接方第三次握手ACK报文，ack值为接收方seq值+1

至此，三次握手结束，双方的tcp连接成功建立

> 为什么不是两次/四次？

两次的问题：

- 对双方的seq值进行接收确认验证

- 防止网络时延导致重复历史的TCP连接建立

四次：

- 没有必要，第二次握手可以将SYN和ACK进行合并

> accept()出现在第几次握手？

在第三次握手之后，客户端句柄由第一次握手时建立，I/O多路复用模型下的服务器主要通过server listen fd接收处理OP_ACCEPT事件进行accept()，并为fd注册OP_READ事件

第一次握手：server为client建立句柄，并放入到syn队列（半连接队列）中

第二次握手：client fd仍旧在syn队列中

第三次握手：将client fd从syn队列移动到accept队列（全连接队列）中

程序的accept()相当于从全连接队列中取出client fd，所以发生在第三次握手之后

> SYN攻击是什么，如何缓解？

恶意连接方发送第一次握手报文后不发送第三次握手报文真正建立连接，从而导致服务器的半连接队列溢出，从而无法正常建立其他TCP连接

缓解方法：
- 指定半连接队列的大小与溢出时的拒绝策略

- syn cookies算法，避免半连接队列占满

4. 四次挥手

- 主动断开方发送第一次挥手FIN报文，随后状态变为FIN_WAIT1

- 被动断开方向主动方发送第二次挥手ACK报文，并开始进行数据收尾处理，主动方接收后状态变为FIN_WAIT2，被动方从ESTABLISHED变为CLOSE_WAIT

- 被动方收尾完毕后，向主动方发送第三次挥手FIN报文，随后状态由CLOSE_WAIT变为LAST_ACK

- 主动方发送第四次挥手ACK报文，随后状态变为TIMED_WAIT，并等待2MSL时长后进入CLOSED状态，被动方接收到ACK后直接进入CLOSED状态

至此，双方连接真正断开

> 为什么是四次不是三次？

FIN表示不再发送数据，但仍可接收数据，主动断开方率先发送第一次挥手仅表示自己数据已处理完毕，不能代表被动方的数据也处理完毕，所以多一次被动方处理数据的时间，就是四次挥手

> 为什么主动方要等待2MSL时长后才能从TIME_WAIT状态进入CLOSED

- 辅助被动方正常关闭连接，2MSL时长恰好能保证被动方至少重试一次FIN包，也避免了后续TCP连接被复用后在一段时间内都无法正常与被动方再次建立连接

- 防止TCP连接复用后，上一次连接中的报文段由于时延到达导致当前连接数据错乱

5. TCP如何保证可靠性

- 校验和checksum，接收方接收到数据后计算checksum并与报文首部的checksum进行对比，不一致说明数据传输有误

- ack应答，有求必应，基于字节流传输的数据都进行了编号，ack则表示当前接收方已接收到的数据序号

- 重传机制：包括快重传和超时重传，前者由重发ack报文值触发，后者则在RTO时间内未接收到ack报文触发，当触发后发送方将重新发送数据

- 流量控制：通信双方都维护发送、接收窗口，接收窗口的大小由应用繁忙程度决定，发送窗口则由对方的接收窗口通告值确定

    - 糊涂窗口：当出现窗口关闭现象后，接收方在稍微缓过来后，又将自己的小窗口通告给对方，对方则会通过小窗口发送小数据，相比TCP + IP首部40字节而言得不偿失

    - 窗口关闭：当接收方处理不过来时，将接收窗口值设置为0通告给对方

- 拥塞控制：TCP是无私的传输层协议，通过拥塞控制来控制发送者的发送窗口增长速率，从而避免出现网络时延时，发送方的数据充斥了整个网络

    控制分为慢启动、拥塞避免和拥塞发生三个阶段，前两个阶段会逐渐降低窗口的增长速率，窗口处于增长状态

    tcp将重传视为及其重要的事件，当出现重传后，会直接降低发送窗口的大小，并重新调整增长速率算法



<!-- 如何保证可靠性？

- 校验和checksum，接收方收到数据后计算校验和，与报文头的checkSum做对比，不一致则表明数据传输有误

- ack确认包，有求必应，基于字节流传输的每个数据都有其序号，ack的值表示接收方当前已接收的数据序号

- 重传机制，包括超时重传和快重传，前者由RTO超时未收到ack包触发，后者由多次重复ack包触发，发送方将重新发送数据

- 流量控制：通信双方维护一个发送窗口和接收窗口，发送窗口值由对方通告的接收窗口值决定，接收窗口值大小则由系统繁忙程度决定

    - 窗口关闭：当一方繁忙处理不过来时，将会把接收窗口设置为0并通告对方。为了避免出现死锁情况，被通告方在长时间未接收到窗口重开报文时，会发送探测报文

    - 糊涂窗口综合症：从繁忙中缓过来后，不会立即将自己的小窗口通告给对方，而是延迟到较大窗口值时再进行通告

- 拥塞控制：TCP是一个无私的传输层协议，为了防止在网络拥堵的情况下无限制的发送数据导致网络更拥堵，会限制发送窗口的增长速率，并从1开始递增。整个控制过程包括：慢启动、拥塞避免和拥塞发生阶段

    TCP将重传视为极其重要的事件，当发生重传时会将发送窗口的值降为1或一半，并需要通过一段时间的恢复才能回复到原来的大小 -->

6. Https：http + SSL/TLS，目前市面上绝大部分https都使用TLS

TLS四次握手：

- Client Hello：客户端发送https请求，携带自身支持的hash算法、加密算法和随机数A

- Server Hello：服务端接收请求后，指定hash算法和加密算法，同时生成随机数B，并将协同CA证书发送给客户端，证书包含公钥

- Client Key Exchange：客户端验证证书的完整性和可靠性，若有问题则进行提示，否则使用A和B生成对称秘钥X，并协同摘要值（由摘要算法得出）经过证书的公钥加密后发送给服务器

- Server Finish：服务器使用私钥解密得到秘钥X，并使用X加密Finish消息发送给客户端，验证握手阶段建立的加解密通道是否正常建立

相比较http明文传输，https有效提高了传输过程的安全性，防篡改，**防冒充（钓鱼节点）**，防窃取

7. GET和POST区别

本质上没有区别，是http应用层协议的两种不同请求方式，在传输层上都基于tcp传输

GET：只读操作，用于获取服务器资源

POST：增删改服务器资源

- 安全性：指服务器资源安全性，数据安全性http明文传输无法保证，需要通过https进行加密传输

    - GET：安全，只读操作不会破坏服务器资源

    - POST：不安全，修改服务器资源

- 幂等：

    - GET：幂等性，执行多少次操作结果都是一样

    - POST：不具备幂等性，多次提交可能会破坏资源，一般由服务器业务逻辑提供幂等性

结论：GET资源安全且幂等，POST资源不安全不幂等，查询上GET速率较快因为**可被缓存**

8. http1.1特性

- 持久连接：任意一段没有明确提出断开连接时，tcp连接将继续保持连接状态

    1.0每发送、响应一次请求后就会断开tcp连接，1.1持久连接大大减少了tcp连接重复建立与断开的开销

- http pipeline：管道化传输，使得发送方可以在上一个请求得到响应前，继续发送下一个请求，但仍要求接收端按序处理返回

    - http队头阻塞：接收方无法识别拼装乱序请求，后续请求的响应会由于队头请求延迟而阻塞，在http2引入帧概念进行解决

    - 缺点：关闭http pipeline，避免http pipeline接收方队首阻塞，导致小文件传输连接空闲，而大文件传输连接阻塞其他请求，使得整体效率不升反降

主流做法：采用持久连接 + 并行连接，客户端根据每个tcp连接的空闲情况选择发送

9. 负载均衡有哪几种方式？

- dns：不同地理区域的用户通过dns域名解析到不同的ip地址，由域名服务商提供，扩展性差，控制权在运营商

- http重定向：发送302重定向报文，将负载算法得到的应用服务器地址填充在Location字段中，性能差会产生二次请求

- 协议层反向代理：解析http请求得到请求主体ip，通过负载均衡算法得到真实web服务器地址，并将该请求转发到真实服务器上，后续响应通过代理服务器中转返回请求主体

    - 优点：相比http重定向效率更高

    - 缺点：中转性能有瓶颈，且存在进程解析的内存拷贝开销

- IP层反向代理：在进程内核中修改IP头中的目的IP，目的IP由算法得到，进行流转

    - 优点：相比较协议层反向代理，少了进程解析的开销

    - 缺点：依旧中转性能瓶颈

- 数据链路层负载均衡（三角运输）：以LVS为例，配置真实物理服务器集群的虚拟IP与负载均衡服务器IP一致，并通过修改MAC帧的目的地址进行流转，后续真实服务器无需再通过负载均衡服务器，可直接响应客户端

    - 优点：降低中转瓶颈

10. 负载均衡算法？

- 轮询：代理服务器维护递增值，依次分发到不同服务器上

- 最少连接：将请求分发到当前连接处理最少的服务器上，这是最符合负载均衡定义的算法

- 随机

- 散列：通过hash计算出对应真实服务器地址进行转发，形成**会话黏滞**
# interview nine：network

# **1. tcp/ip协议**

1. TCP/IP四层模型

    - 数据链路层：物理手段将主机连接到网络中，将 比特流 分组为 **数据帧**

    - 网络层：主机与主机间通信，采用**IP协议**（路由分组交换）实现**数据包**传输

    - 传输层：**进程**与**进程**间通信（端到端通信），协议包括 TCP、UDP、QUIC、ICMP

        - TCP：面向连接，是**基于字节流**的可靠传输层通信协议

            - 面向连接：点对点连接，UDP则是同时向多个主机发送消息

            - 字节流：有序、重复丢弃、无边界

            - 可靠：TCP尽可能保证报文到达接收端

    - 应用层：协议实现，数据转换，建立连接，协议包括 HTTP、FTP

2. **TCP报文**段：包括TCP首部 + 数据

    首部包括序列号（seq）、确认号（ack）、控制位（ctl）、窗口

    - seq：发送方发送数据字节流的标识，首部中的序号值是**本报文段数据**第一个字节在整个TCP连接中的数据序号。使用随机算法初始化值，防止**复用旧连接**后导致数据错乱

        > **因此，seq根据数据长度来增加，当没有数据时则+1**

    - ack：接收方响应的确认号，也表示期望收到对方下个报文段第一个字节的序号

    - ctl

        - SYN：前两次握手的建立控制位，由于是双向通信所以双方的第一次发送都会携带

        - ACK：有求必应，否则会触发发送方的超时重传机制

        - FIN：关闭连接的第一、三次挥手

# **2. TCP三次握手**

1. client向server发送SYN报文（seq=client_isn）

    - client：SYN_SEND

2. server接收到SYN报文段，并发送SYN+ACK报文段（seq=server_isn，ack=client_isn + 1），表示接收到了发起方的连接请求

    - server：由LISTEN进入SYN_RCVD

3. client接收到server的ack，再返回ACK报文段给server（seq=client_isn + 1, ack=server_isn + 1）

    - client: 由SYN_SEND进入ESTABLISHED

server最终接收到第三次握手后，进入ESTABLISHED

**问题1：为什么不是2次握手？**

- 阻止**网络时延**造成server对**重复、历史**的连接初始化

    当网络出现时延时，即第一次握手和第二次握手超过RTT（往返时间）后，发起方将触发`超时重传`，产生新的第一次握手包建立连接（四元组已换）
    
    如果没有client的第三次握手，server端只能为client全部重传的握手包都建立连接，产生重复的历史连接
    
    > 这种思路就是通过第三次握手，提供给client纠正的机会，由client检查错误ack并提供RST报文给服务端进行修正

- 确保双方的初始化序列号都已正确同步

    对于server端而言，如果没有第3次握手，将无法确保自己的seq被client端正确接收

**问题2：为什么不是4次握手？**

3次就够了，第二次握手中server端可以同时发送SYN位和ACK位的数据包

**问题3：程序的accept()发生在三次握手的哪个阶段**

> 在第三次握手完成后，不要被哪个阶段误导了

- `第一次握手`：server为client新建socket句柄，将句柄放入到内核的半连接队列中（syn队列）

- `第三次握手`：将句柄从syn队列中移除，加入到全连接队列中（accept队列）

- **`第三次握手之后`** accept()：程序将句柄从全连接队列中取出

**问题4：建立和处理连接用的是同一个socket吗？**

建立连接：listen_socket_fd

处理连接：client_fd

**问题5：SYN攻击（syn flood）是什么？如何缓解？**

恶意client发送第一次握手后，不发送第三次握手，通过这种方式启动大量恶意client占满**server半连接队列**，进而使server无法再为其他client建立连接

缓解手段：

1. 指定半连接队列大小、队列溢出拒绝策略（如发送RST报文回拒client）

2. 启用syn cookies算法

- server接收到第一次握手，不直接为client创建句柄放入半连接队列中，转而通过syn cookies算法计算出随机值，填充到seq中返回给client

- 如果client是正常建立连接，server就可以接收到第三次握手，再通过syn cookies算法反解出client第一次握手时的数据。后续为请求建立句柄，并放入全连接队列

# **3. TCP四次挥手**

1. 第一次挥手：主动方发送FIN报文给被动方请求结束连接

    主动方状态：ESTABLISHED变为FIN_WAIT1

2. 第二次挥手：被动方接收FIN报文后，向客户端发送ACK报文，并开始进行数据收尾处理

    主动方状态：FIN_WAIT1变为FIN_WAIT2（接收到被动方的ACK报文）
    
    被动方状态：ESTABLISHED变为CLOSED_WAIT

3. 第三次挥手：**被动方处理数据完毕**，发送FIN报文给主动方

    主动方状态：FIN_WAIT2变为TIME_WAIT（接收到被动方的FIN报文）

    被动方状态：CLOSED_WAIT变为LAST_ACK

4. 第四次挥手：主动方接收到被动方的FIN包后，向被动方发送ACK，**确保被动方可以正确关闭**，并**等待2MSL**后进入CLOSED状态

    主动方状态：**TIME_WAIT**在**2MSL**后，自动变为CLOSE

    被动方状态：**LAST_ACK**变为CLOSE（接收到主动方的ACK报文）

**问题1：为什么要4次挥手**

FIN包：当前发送方已经没有数据要发送，但**仍可接收数据**

相较握手建立连接阶段SYN和ACK可以合并发送。在结束连接时，**被动关闭方通常还有数据收尾处理工作**，所以其ACK和FIN需要分开来进行发送

**问题2：为什么主动关闭方还需要等待2MSL后才能进入CLOSED状态**

MSL：数据包在网络发送中的最大生存时间，超过该时间的数据包将直接被丢弃掉

2MSL：确保网路上**一来一回**的历史报文段，都已超时失效

1. 数据安全性

    防止tcp连接复用之后，**历史连接**的时延数据包影响**当前连接**数据正确性，等待2MSL可以保证极限情况下**一来一回**的历史数据肯定都失效了

2. 辅助被动关闭方正确进入CLOSED状态，**被动方在没有收到第四次挥手时，至少可以进行一次FIN包重试**

    如果主动方接收到FIN包后就进入CLOSED状态，恰好第四次挥手网络丢失，那么被动方将无法保证自己的FIN包是否被主动接收，从而进入长时间的LAST_ACK状态，**导致该连接在很长一段时间都无法复用**

# **4. TCP可靠性**

1. 校验和（check sum）：接收方接收到数据后计算一遍check sum1，并与header中的check sum2进行对比，若两个校验和不一致，说明数据传输有误

2. 确认应答机制（ack）：有求必应，基于字节流传输的tcp连接对每个数据都进行了编号，ack的值表示接收方当前接收的数据序号

3. 重传机制：当发送方没有收到对方的ack包（超过RTO时间，RTO值略大于RTT值）或ack包返回值出现重复时，将通过`超时重传`或`快速重传`等机制，重发数据报文

    - 超时重传：当超过指定时间没有接收到对方的ACK确认应答报文后，就会重发该数据（超过RTO时间，RTO值略大于RTT值）

    - `快速重传`：重传机制之一，不以时间为驱动，而是以确认信息数据驱动进行重传。发送方在**收到`三个连续相同`的ACK响应后会触发快速重传机制**

        - D-SACK：接收缓冲区地图，记录不连续块的序号情况，用于确定缺失部分的数据（否则全部重传效率低）

    > 缓解超时重传触发时间过久，可以提前发现丢包现象进行修复

    TCP将超时重传视作相当重要的事件，当出现超时重传时，会增大RTO的退避因子（降低重试频率），并减少发送窗口大小限制发送速率

> 流量控制是避免发送方填满接收方的缓存，而拥塞控制是为了避免发送方的数据填满整个网络

4. 流量控制：通过滑动窗口提升网络通信效率，应答方通过**累计应答机制**减少应答次数，并将自己的接收窗口填入TCP首部中通告对方，对方的发送窗口变为接收方的接收窗口值，通过该窗口值限制发送速率

    - 累计应答：累计ACK，TCP并不是每一个报文段都会回复ACK的，可能会对两个报文段发送一个ACK，**可以减少ack的次数**

    - 发送/接收窗口（TCP窗口）：共两组（通信是双向的），用于提升网络通信效率，通过指定窗口的大小，在窗口内容未达到最大值时，可以无需等待确认应答可以继续发送数据

        - 大小：初始值建议10个MSS大小，后续会等于对方对应窗口的通告值（A发送 == B接收，A接收 == B发送）
            - MSS：传输层中，除去IP header和tcp header后，一个报文最大能容纳的tcp数据长度
            - MTU：一个网络包的最大长度，一般以太网为1500字节

        - 算法：滑动窗口，通过左、右边界指针进行滑动，两个指针间的距离为当前窗口大小值
            - 左边界：收到ACK则增长
            - 右边界：左边界 + 当前窗口大小值

    - 窗口关闭：可能出现0窗口通告值，会通过计时器发送窗口探测报文，防止通信双方陷入瘫痪
    - 糊涂窗口综合症：应用处理上来后，开始出现富余但不多的窗口值，此时立刻通告对方后，又迅速被对方塞满导致窗口关闭，最终会导致产生大量小包发送，效率极低
        - 发送方：
            - 使用nagle算法，本质也是延迟响应，在未满足以下条件时囤积数据
                - 直到发送缓冲区的数据 达到 一个MSS，或对方窗口 达到 一个MSS
                - 收到之前发送数据的ack回包（对方有窗口值，才能接收到数据，也才能返回ack）
        - 接收方：
            - delay ack延迟响应
            - 等待窗口大小满足大于等于MSS，或大于等于缓存空间一半，再发送窗口通告

5. 拥塞控制：控制发送窗口的增长速率，当出现快速重传/超时重传时，会降低窗口值cwnd与增长阈值ssthresh，通过恢复阶段后才能恢复到原先的窗口大小
    
    - 慢启动：cwnd < ssthresh，cwnd = cwnd + 1，曲线指数型增长
    - 拥塞避免：cwnd > ssthresh, cwnd = cwnd + 1 / cwnd，曲线线性增长
    - 拥塞发生：降低ssthresh和cwnd
        - 超时重传：
            - cwnd = 1，ssthresh = cwnd / 2
            - 恢复过程：慢启动
            - 曲线断崖式下跌后，根据慢启动呈现指数型曲线
        - 快速重传（快速恢复）
            - cwnd = cwnd / 2, ssthresh = cwnd
            - 恢复过程：收到新的ack包进入拥塞避免的增长曲线，收到重复的ack包进入慢启动的增长曲线

# **5. 浏览器请求一个网站的过程**

1. 用户在浏览器中输入请求网站的URL

1. 浏览器向**dns服务器请求解析对应域名，获得IP地址**
    
    - 如果本地缓存有该域名的ip地址，则直接返回浏览器；如果没有，则以递归的形式向整体dns系统请求解析，获取结果后应答浏览器

    - cdn
        - local dns先向授权dns服务查询，获取对应域名cdn（阿里云DNS调度中心）的ip地址A
        - 域名解析请求转发到地址A后，分配到目标的最佳节点IP地址，返回local dns
        - local dns返回浏览器最佳节点IP地址

3. 浏览器对ip地址发出请求

4. 通过子网掩码判断IP地址是否处于同一个子网，如果是同一个子网可直接连接，否则需要经过路由器、交换机的传输

5. `与目标主机建立TCP连接`

6. 连接建立成功后，应用层构造http请求报文，传输层添加tcp首部，IP层添加IP头，数据链路层添加以太网协议首部

7. 交互完毕，后续会与目标主机断开TCP连接

# **6. HTTPS的工作原理（安全证书交换过程）**

HTTPS：HTTP + TLS（SSL/TLS），默认端口为 **443**

> 目前市面上所有HTTPS使用TLS而不是SSL，TLS是SSL的更新版本，修复了早期SSL的一些安全 漏洞

传输层TCP三次握手后，再进行**应用层TLS四次握手**，后续数据加密传输（**前两个步骤为明文传输**）：

1. Client Hello：客户端向服务器发起https连接请求，携带自身支持的hash算法、加密算法、随机数A

2. `Server Hello`：服务器选择client支持的hash算法和加密算法，同样产生一个随机数B，协同服务器证书（证书内包含公钥）发送给客户端

3. `Client Key Exchange`：客户端检查证书的完整性和安全性
- 若有问题则提示警告
- 若无问题，则通过之前的随机数A、B，生成对称加密秘钥 **X**
- 通过摘要算法计算上述内容的摘要值，使用证书公钥进行加密（后续客户端加解密数据都使用X）

4. Server Finish：通过X加密一段Finish消息发送给客户端验证加解密通道是否成功
- 使用server私钥解密得到对称密钥 **X**，
- 使用client公钥解签获取摘要
- 通过内容反计算出摘要值，防止篡改

后续通信过程都采用X和约定好的加密算法进行加解密，得到最终的网页内容

相比较http明文传输，https有效的提升了传输过程的安全性，**防篡改（签名）**，**防窃取（加密）**，**防冒充（证书，防钓鱼节点）**

# **7. GET与POST区别**

本质上没有区别，是http**应用层**协议的两种不同请求方式，在传输层都基于**tcp传输**

GET：获取服务器资源，只读操作

POST：增删改服务器资源

- **安全性**：指服务器的**资源安全**（通信数据在http明文传输下无法保证，需要https加密传输保证）

    - POST：资源不安全，会修改服务器上的资源

    - GET：资源安全，只读操作不会破坏资源

- **幂等性**：

    - POST：不幂等，多次执行结果不一致，可能会破坏服务器资源，一般由**服务器提供幂等机制**

    - GET：幂等，只读查询执行几次结果都是一样的

结论：
- GET资源安全且幂等，POST资源不安全且不幂等
- GET效率更高因为其可被浏览器缓存
- 查询数据使用GET，增删改数据使用POST

- GET和POST在不同浏览器上，TCP报文发送方式不同
    - GET普遍一个报文：http header和data合并成一个
    - POST分为两个报文：先发送http header，server返回101 continue后，再发送一个data

- **GET的数据只支持ASCII字符，拼接在url上，长度有限制最大为2048个字符（URL长度限制）；POST没有长度限制，也支持二进制**

- 现实安全性而言，GET会把数据拼接在url上，可能会被人窥见

# **8. http1.1特性**

- 持久连接：**任意一端**没有提出明确断开连接，则保持tcp连接状态

    1.0每次请求结束后都会断开tcp连接，1.1持久连接大大减少了重复建立和断开连接开销

- http pipeline：管道网络传输，指允许客户端在已发送请求收到服务器响应前，发送下一个请求，但服务端仍旧按照请求发送的顺序返回响应

    - 队头阻塞：指由于上一个请求未发送/接收完毕，导致后续的请求被阻塞

        接收方无法识别拼装乱序请求，后续请求的响应会由于队头请求延迟而阻塞，在http2引入帧概念进行解决

    - 缺点：http pipeline接收方队首阻塞，导致小文件传输连接迅速完成任务进入空闲，而大文件传输连接延迟导致其他请求阻塞，整体效率不升反降

所以基本关闭http pipeline，主流的做法是：持久连接 + 并行连接，客户端可以根据各个连接的完成情况，**自主**选择空闲的tcp连接进行传输

# **9. 负载均衡有哪几种实现方式**

1. DNS

    - 分层：应用协议层（请求dns域名解析）

    - 负责主体：域名服务商的dns服务器
    
    - 效果：实现**地理级别**的负载均衡，不同地区的用户通过DNS解析返回不同地址
    
    - 缺点：控制权在域名服务商，扩展性差

2. HTTP重定向

    - 分层：应用协议层

    - 负责主体：http重定向服务器

    - 返回302响应并修改http响应头的Location达到负载均衡

    - 缺点：
    
        - 性能差，**产生二次请求增加请求耗时**

        - 请求响应都由http重定向服务器中转，性能有瓶颈

3. 协议层反向代理

    - 分层：应用协议层

    - 负责主体：反向代理服务器（Ngnix）

    - 反向代理服务器**解析请求**，获得客户端请求的主体IP，并通过均衡算法得到真实web服务器地址并转发该http请求

    - 优点：反向代理隐藏了真实服务器的ip地址，且相比http重定向少了一次请求

    - 缺点：请求响应都由反向代理服务器中转，性能有瓶颈

4. IP层反向代理

    - 分层：网络层 + 传输层

    - 负责主体：反向代理服务器

    - 直接**在内核**对数据包的IP地址和端口进行修改，并根据负载算法计算真实web服务器地址后进行流转

    - 优点：相比协议层反向代理少了解析请求的开销

    - 缺点：请求和响应，依旧都由反向代理服务器中转

5. **数据链路层负载均衡（lvs 三角传输）**

    - 分层：数据链路层

    - 负责主体：负载均衡服务器

    - 分发过程中不修改IP地址，转而修改目的mac地址，且**配置真实物理服务器集群所有机器虚拟IP与负载均衡服务器IP地址一致**，做到响应数据可直接由**处理主机**返回到用户浏览器，形成三角形关系

    - 优点：仅在请求分发时由反向代理服务器中转，响应数据可直接返回，降低了负载均衡服务器性能对整个系统性能的影响

# **10. 负载均衡算法**

1. 源地址散列：对IP地址进行hash计算，得到应用服务器，来自同一个IP地址的请求总在同一个服务器上处理，形成会话黏滞

2. 最少连接：将新到的请求分发到最少连接的服务器上，是最符合负载均衡定义的算法，但并不是效果最优

3. 随机

4. 轮询：由负载服务器维护递增数，依次分发到每台应用服务器上

# 参考
- [epoll空轮询](https://www.jianshu.com/p/3ec120ca46b2)
- [常考的 BIO，NIO，AIO 总结](https://blog.csdn.net/m0_38109046/article/details/89449305)
- [get请求可以被缓存](https://segmentfault.com/q/1010000021784624)
- [TLS四次握手](https://zhuanlan.zhihu.com/p/156034207)

- [浏览器中网址访问过程](https://blog.csdn.net/m_buddy/article/details/77800998)

# 重点参考
- [网络篇夺命连环12问](https://mp.weixin.qq.com/s?__biz=MzkzNTEwOTAxMA==&mid=2247488227&idx=1&sn=36587eab67d87824179dd5edda3533db&chksm=c2b25a1ef5c5d308ae02ba5a2e5922738fd43305faf74c41320272acecc77d6a155eb50ad33a&token=982147105&lang=zh_CN&scene=21#wechat_redirect)
- [TCP队头阻塞和HTTP队头阻塞](https://blog.csdn.net/weixin_34364071/article/details/91416530)
- [java BIO/NIO的accept()方法](https://blog.csdn.net/Tom098/article/details/116107072)
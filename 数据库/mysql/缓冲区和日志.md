# Mysql（四）：运作机制

> [Mysql（一）：innodb存储](https://asea-cch.life/achrives/innodb存储)

> [Mysql（二）：索引](https://asea-cch.life/achrives/索引)

> [Mysql（三）：锁机制](https://asea-cch.life/achrives/锁机制)

上两篇文章主要介绍了innodb的外存存储和索引机制，我们深刻地感受到I/O操作对于系统的性能至关重要，Mysql使用B+树组织数据，并贯彻系统局部性原理，最小操作单位为一个页，以尽可能地减少对库操作时I/O的次数

那么在软件层面上，Mysql运作机制又是什么？

![逻辑架构](https://asea-cch.life/upload/2021/06/%E9%80%BB%E8%BE%91%E6%9E%B6%E6%9E%84-4702c42811ee452fa842577bf56fd56a.png)

Buffer Pool对应图中的**查询缓存**，处于内存区域，是数据库对磁盘读写进行缓存加速的机制。它使得操作不会立即反馈到磁盘上，而是先操作缓存，极大程度提高数据的访问速度

![缓冲池和日志文件结构](https://asea-cch.life/upload/2021/06/%E7%BC%93%E5%86%B2%E6%B1%A0%E5%92%8C%E6%97%A5%E5%BF%97%E6%96%87%E4%BB%B6%E7%BB%93%E6%9E%84-b4d927e2591d465197630da28169e012.jpg)

上图中与磁盘文件平行的，就是数据库的日志系统，它是数据库的重要保护机制，数据库事务通过日志系统与锁机制共同实现原子性、持久性和隔离性，进而保证了业务数据的一致性

# **1. Buffer Pool**

![bufferPool结构](https://asea-cch.life/upload/2021/06/bufferPool%E7%BB%93%E6%9E%84-ab9d2f8d4e194de388ef16c3df61eaf7.jpg)

## **1.1 数据页刷盘规则**

缓冲区中未刷到磁盘的数据称为脏数据（dirty data），因为数据和日志**都以页**的形式存在，所以脏页表示脏数据和脏日志

**在innodb中，数据刷盘的规则只有一个：checkpoint，checkpoint触发后，会将buffer中脏数据页和脏日志页都刷到磁盘中**

## **1.2 checkpoint**

checkpoint分为两种：
- sharp checkpoint：在重用redo log文件（例如切换日志文件）时，将所有已记录到**redo log中对应的脏数据页**刷到磁盘
- fuzzy checkpoint：一次只刷一小部分的日志到磁盘，而非将所有脏日志刷盘
    - master thread checkpoint：由master线程控制，**每秒或每10秒**刷入一定比例的脏页到磁盘
    - flush_lru_list checkpoint：保证lru列表有可用的空闲页的checkpoint，cleaner线程会专门负责脏页刷盘
    - async/sync flush checkpoint：同步刷盘或异步刷盘
    - dirty page too much checkpoint：默认脏页占75%时，强制刷一部分脏页到磁盘

由于刷脏页为IO操作，需要一定的操作时间，所以checkpoint的位置是**在每次刷盘结束之后才在redo log中标记的**

    这意味着使用show engine innodb status指令时，恰好在checkpoint点但未刷盘完毕，可以看到log flushed up > pages flushed > last checkpoint at的情况

# **2. 日志系统**

binlog是**MYSQL数据库层面**的日志，也就是我们常说的二进制日志，不管是什么存储引擎，对数据库进行修改都会产生二进制日志



undo.log/redo.log是**InnoDB存储引擎**的日志，即只有使用了innodb引擎才会产生，数据修改时不仅记录redo，还记录相对应的undo

事务的隔离性由锁策略决定（undo日志提供MVCC作为辅助），原子性和持久性则由undo/redo日志完成，他们共同构筑了事务的一致性

## **2.1 redo.log**

别名：重做日志

作用：提供事务**持久性**

组成部分：
- 在内存中的日志缓冲（redo log buffer），具有易失性
- 在磁盘上的重做日志文件（redo log file），具有持久性

### **2.1.1 结构**

### **日志组（log group）**

```sql
# 输出日志系统的信息
show global variables like 'innodb_log%';
```

![redo日志组和日志文件大小](https://asea-cch.life/upload/2021/06/redo%E6%97%A5%E5%BF%97%E7%BB%84%E5%92%8C%E6%97%A5%E5%BF%97%E6%96%87%E4%BB%B6%E5%A4%A7%E5%B0%8F-1b768fb56f5340b5b6b15adb35f0ecbd.png)

> 上图表示redo日志组由4个log_file组成，每个log_file的大小为268435456字节（256MB），所以该日志组的整体大小为1GB

redo日志组是固定大小的，以**环状**的方式对组内的文件进行链接，在innodb将log buffer中的redo log block刷到这些log file中时，会以追加写入的方式**循环轮询写入**

在日志组第一个log_file（ib_logfile0）的尾部进行追写，直到满了后向下一个log_file（ib_logfile1）写，当最后一个log_file也写满了，则会清空一部分第一个log_file，以此类推

![logfile文件](https://asea-cch.life/upload/2021/06/logfile%E6%96%87%E4%BB%B6-fa1b23c41e4b4b98befa7a253120d9b1.png)

    redo log file的大小对innodb的性能影响巨大，设置过大会导致恢复时间较长，设置太小会导致写redo log时循环切换redo log file

![group和redolog磁盘文件](https://asea-cch.life/upload/2021/06/group%E5%92%8Credolog%E7%A3%81%E7%9B%98%E6%96%87%E4%BB%B6-24c2187fca6a4c8e965a07a1c54574e0.png)

#### **日志块（log black）**

redo log buffer、os buffer和磁盘redo log文件都是以**日志块为单位**进行存储，与磁盘扇区大小一致，每个块**占512字节**，这样可以保证**写日志扇区的操作是原子**

![logblock，图有误，Log Block理论上只有492字节](https://asea-cch.life/upload/2021/06/logblock-ef66d07c6a4f446292550b1eab965797.png)

当一个数据页产生的变化需要使用超过492字节的redo log记录，则会使用多个redo日志块记录数据页的变化

#### **日志格式（redo log）**

在日志块中讲到了真实记录的空间只有492字节，这492字节又被分为了四大部分，以记录数据页的变化：
- redo_log_type：占用1字节，表示redo log的日志类型
- space：表空间ID
- page_no：页偏移量，用于定位修改的数据
- redo_log_body：表示当前重做日志的数据部分，其结构根据dcl类型动态变化

![redolog的插入和删除](https://asea-cch.life/upload/2021/06/redolog%E7%9A%84%E6%8F%92%E5%85%A5%E5%92%8C%E5%88%A0%E9%99%A4-fa6296c2999c48e7a9011a69c92ec972.png)

### **2.1.2 实现机制**

`Writing Ahead Logging`：简称WAL，即先写日志，再写数据

`Force Log At Commit`：在事务提交时，**必须先**将该事务的所有事务日志写入到磁盘上的redo log file和undo log file中进行持久化，以保证断电后的灾难恢复

### **2.1.3 刷盘机制**

上述两种机制其实代指同一种，核心思想都是**先写日志**，从日志缓冲写入内核buffer，再从os buffer写入到真实磁盘log文件

![redo和undo日志的写入](https://asea-cch.life/upload/2021/06/redo%E5%92%8Cundo%E6%97%A5%E5%BF%97%E7%9A%84%E5%86%99%E5%85%A5-8aa7859c7c5d476fa6f5f56773c08155.png)

> [深度好文，讲解了日志写盘的机制与流程](https://www.cnblogs.com/f-ck-need-u/archive/2018/05/08/9010872.html#auto_id_2)

可以看到os buffer作为写操作的缓冲区，这是因为open磁盘的日志文件时，**没有使用O_DIRECT标志位**，这意味着不会IO直写到底层存储设备。而是等待缓冲区到了一定容量后，或者显式地调用fsync()方法，才会冲刷缓冲区数据到磁盘中，这可以**减少I/O写盘次数**

    比如写abcde，如果开启了O_DIRECT，需要5次调用，而如果没有开启标志位，则只发起一次系统调用

刷日志到磁盘有以下规则：

1. 根据innodb_flush_log_at_trx_commit的策略决定事务提交后如何刷日志

    ![事务提交时redo的策略](https://asea-cch.life/upload/2021/06/%E4%BA%8B%E5%8A%A1%E6%8F%90%E4%BA%A4%E6%97%B6redo%E7%9A%84%E7%AD%96%E7%95%A5-41c7e47195d1408d9d82f11948533f92.png)

    - 值为0，每次提交都写到log buffer，每秒写入os buffer并调用fsync()写入磁盘（耗时最短，无论mysql服务还是系统挂掉，事务都将全部丢失）
    - 值为1，每次提交直接写到os buffer，并立即调用fsync()（耗时最长，安全）
    - 值为2，每次提交都写到os buffer，每秒再调用fsync()（耗时居中，mysql服务挂掉只丢失未提交事务，无法保证系统宕机）

2. 每秒刷一次，这个刷日志的频率由变量`innodb_flush_log_at_timeout`值决定，默认一秒，该策略与commit无关
3. 当log buffer内存使用超过一半时
4. **当有checkpoint，checkpoint在一定程度上代表了刷到磁盘时日志所处的LSN位置**

### **2.1.4 宕机恢复**

#### **LSN**

全称日志的逻辑序列号（log sequence number），在innodb存储引擎中占用**8个字节**，值会随着日志的写入而逐渐增大

```sql
show engine innodb status;
```

![lsn](https://asea-cch.life/upload/2021/06/lsn-cc3fd8ec38564184bbb1dd74a917df93.png)

- log sequence number：目前日志系统的lsn编号
- log flushed up to：已经刷到redo log on disk上的lsn编号
- pages flushed up to：已经刷到数据页上lsn值的编号
- last checkpoint at：上一个checkoutpoint对应的lsn编号

作用：
- 获取检查点的位置
- 获取数据页的版本信息
- 获取写入日志总量，通过LSN开始号码和结束号码可以计算出写入的日志量

存在位置：redo log / 数据页的头部（记录了当前页最终的LSN值是多少）

如何记录：

> 1. 修改内存中的数据页，并在数据页中记录LSN，称为data_in_buffer_lsn

> 2. 在修改数据页的同时，向redo log in buffer中写入redo log，并记录下对应的LSN，称为redo_log_in_buffer_lsn

> 3. 写完buffer中的日志后，当触发了日志刷盘规则时，会向redo log file on disk刷入重做日志，并在该文件记下对应LSN，称为redo_log_on_disk_lsn

> 4. WAL，即预写日志记录完成后，在某些情况触发checkpoint，会将内存中的脏页（数据脏页和日志脏页）刷到磁盘。在本次脏页刷盘结束后，会在redo log中记录checkpoint的LSN位置，称为checkpoint_lsn

>5. 在checkpoint刷入的每个数据页都会记下当前页所在的LSN，称为data_page_on_disk_lsn

![刷盘详情](https://asea-cch.life/upload/2021/06/%E5%88%B7%E7%9B%98%E8%AF%A6%E6%83%85-d335eba993df460ca02b8df872442203.png)
    
time_line_1：修改内存数据页

    log sequence number：110
    log flushed up to：100
    pages flushed up to：100
    last checkpoint at：100

time_line_2：修改内存数据页，同时触发redo每秒刷盘的策略

    log sequence number：150
    log flushed up to：150
    pages flushed up to：100
    last checkpoint at：100

time_line_3：修改内存数据页

    log sequence number：300
    log flushed up to：150
    pages flushed up to：100
    last checkpoint at：100

**time_line_4：到达checkpoint，开始刷脏页，刷脏页过程中控制刷日志页比刷数据页进度更快，如果**

        log sequence number：300
        log flushed up to：259
        pages flushed up to：234
        last checkpoint at：100

time_line_5：刷盘完成，全部lsn一致

    log sequence number：300
    log flushed up to：300
    pages flushed up to：300
    last checkpoint at：300

time_line_6：触发redo刷盘策略，但是刚刚才进行了checkpoint刷盘，没有新增日志

time_line_7：插入数据，修改内存数据页

    log sequence number：800
    log flushed up to：300
    pages flushed up to：300
    last checkpoint at：300

time_line_8：事务提交结束

    如果log_trx_commit策略为1，则直接触发fsync()：
    log sequence number：800
    log flushed up to：800
    pages flushed up to：300
    last checkpoint at：300

    如果log_trx_commit策略为0，则无操作

    如果log_trx_commit策略为1，则将os buffer的lsn修改为800，但redo log磁盘文件仍旧没变动

#### **根据LSN宕机恢复**

恢复重启innodb时，checkpoint表示已经完整刷到磁盘上数据页的LSN，因此仅需要**恢复从checkpoint开始的日志部分**

> 例如：当数据库在上一次checkpoint的LSN为10000时宕机，且事务已经是提交状态，重启数据库时会检查磁盘中数据页的LSN，如果数据页的LSN小于redo log的LSN，则从上一个checkpoint开始恢复

如果宕机过程处于刷盘过程，且数据页的刷盘进度超过了日志页的刷盘进度，这时候一宕机，数据页LSN大于日志LSN，在重启时会检查到大于的这一部分，不会redo

因为redo log记录的是数据的物理变化状态，不记录中间过程，所以**恢复时候会更快**

> 例如：如果是设置innodb_flush_log_at_trx_commit为2，则恢复时会丢失1秒的已提交数据，但是因为redo log是写入到os buffer中的，所以通过日志找回这1秒的数据

## **2.2 undo.log**

提供以下两个功能：
- 确保事务的**原子性**，保存了事务发生前的多个版本，可以用于回滚

- MVCC（**多并发控制版本**）的实现支持，以实现非锁定的一致读

如果因为某些原因导致事务失败，或选择回滚，则借助undolog进行回滚

undo log和redo log记录物理日志不一样，他是逻辑日志，记录的是**操作**

> 例如：可以认为当delete一条记录时，undolog会记录一条对应的insert记录，反之亦然，当update记录一条记录时，undo则记录一条与之相反的update记录

    undolog也会产生redolog，因为undolog也需要实现持久性

### **2.2.1 存储方式**

undolog是采用段（segment）的方式来记录的，每个undo操作在记录时占用一个undolog segment，一个回滚段（rollback segment）中有1024个undolog segment

```sql
# 查看undo相关的变量
show variable like '%undo%';
```
![undo相关变量](https://asea-cch.life/upload/2021/07/undo%E7%9B%B8%E5%85%B3%E5%8F%98%E9%87%8F-630486158782479c85980bca93481406.png)

- innodb_undo_logs：回滚段的个数，默认128个，每个回滚段有1024个undolog segment
- innodb_undo_directory：通过变量innodb_undo_directory来自定义存放目录，默认是`./`，即在`dataDir`。如果开启了innodb_file_per_table，则放在每个表的.ibd文件中
- innodo_max_undo_log_size：undo日志文件的最大容量，默认1GB

### **2.2.2 机制**
当事务提交时，innodb不会立即删除undolog，因为后续还可能使用到undolog；在事务提交后，会将事务对应的undolog放入删除列表中，在后续的purge中删除

> 如RR隔离级别，事务读取的快照读是开启事务时的最新提交行版本，主要事务不结束，该行版本就不能删除，即undolog不能被删除

提交事务时，会判断undolog分配的页是否可重用，如果可，则分配给后面的事务，避免为每个独立的事务分配独立的undolog页而浪费空间和性能

insert：反向记录删除行
delete：实际上不会删除行，而是对delete对象打上删除标记，最终通过purge操作删除
update：
- 如果不是主键列，则反向记录是如何update的
- 如果是主键列，先删除该行，再插入一行目标行，以重新组织聚簇索引

## **2.3 binlog**

> [binlog（二进制日志）](https://www.cnblogs.com/f-ck-need-u/p/9001061.html#blog5)

二进制日志在Mysql的server层面上，不代表它只记录innodb日志，也包含其他的存储引擎

> 本身binlog就是一个历史遗留产物，在以前myisam时只有binlog，在后续加入了redolog后，binlog便主要用于主从复制/级联同步

记录形式：以事件作为记录形式，包含了时间、事件开始和结束位置等信息，本身不是事务日志，但可能是基于事务的innodb二进制日志

写入时机：记录引起或可能引起数据库变化的事件信息（无论是否匹配成功），但绝不包含select或show这种查询语句。如果是基于事务而言，**只在事务提交的时候一次性写入，提交前每个二进制日志记录都先cache（即一个事务可能包含多个二进制日志），在提交时写入**

![二进制日志目录文件](https://asea-cch.life/upload/2021/07/%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%97%A5%E5%BF%97%E7%9B%AE%E5%BD%95%E6%96%87%E4%BB%B6-7721b84e89e04b06a38663d474c8a85d.png)

> binlog.index为二进制日志索引文件，当二进制日志文件滚动时，会向该文件写入对应的信息，其余的就是二进制日志，最大值通过`max_binlog_size`进行设置（默认值为1GB）。对于基于事务的innodb二进制日志而言，事务不可能跨文件记录，如果正好到达最大值但事务还未提交，则不会滚动日志而是继续增大日志

    一般处于安全和功能考虑，不会将二进制日志和datadir放在同一磁盘，因为二进制日志文件增长迅速，且可以明文查看，不具备安全性

### **2.3.1 binlog格式**

在Mysql5.1之前，只有基于Statement形式的日志记录格式，即将**所有相关操作记录为SQL语句记录**，在5.1之后总共有MIXED、STATEMENT、ROW三种格式选择，目前默认为使用ROW格式

#### **Statement**

记录方式：相关操作的**SQL语句**形式

优点：节省日志量，比如范围条件的操作只会有一条

缺点: 主从不一致，使用某些函数会出现问题

> Mysql默认隔离级别是RR的原因：因为RC配合Statement行格式将出现主从复制不一致的情况

因为binlog记录的顺序是以事务提交时一次性写入，这也意味着通过binlog进行同步操作时，是以事务提交次序进行操作的，这可能会导致与实际操作不符

#### **ROW**

记录方式：基于行来记录，将相关行的每一列的值都在日志中保存下来

优点：安全，主从复制一致

缺点：日志量巨大，范围条件的操作不像Statement只有一条日志，而是涉及到的数据都将会有一条日志

#### **MIXED**

Statement和Row混着使用，由Mysql自己决定使用，在以下情况采用Row格式记录日志：

1. 表的存储引擎为NDB，这时对表的DML操作都会以row的格式记录

2. 使用了uuid()、user()、current_user()、found_rows()、row_count()等不确定函数。但测试发现对now()函数仍会以statement格式记录，而sysdate()函数会以row格式记录

3. 使用了insert delay语句

4. 使用了临时表

### **2.3.2 刷盘机制**

binlog cache是binlog对应在内存上的缓冲区，刷盘机制与buffer pool/redo log in buffer类似，由sync_binlog参数控制

```sql
# binlog刷盘操作的频率，为0表示由文件系统控制，为N则表示N次事务提交后刷盘
show variables like 'sync_binlog';
```

sync_binlog = 1时最安全，表示每次事务提交都刷盘，这样在掉电情况下，只会丢失在正在刷盘过程中的事务；而在服务宕机或系统宕机中保证安全，但是IO性能会显著下降

#### **binlog组提交**

内部XA事务：先对redo的prepared写，再对binlog对二进制日志的写，最后对redolog的commit写，整个操作过程是原子的

> [binlog组提交实现原理](http://blog.itpub.net/15480802/viewspace-1411356/)

2PC提交过程：

1. 准备binlog写

    - 请求释放之前的锁

2. 对redo日志的prepared写

    - 往log buffer写入prepare记录
    - 调用fsync()，刷盘prepare record，redo事务未提交

3. 提交binlog的写（binlog刷盘）

    binlog刷盘细化为三个阶段，**每个阶段都有lock保护**，这三个阶段负责批量读取binlog并调用fsync，以**同样顺序组提交**事务：

    第一个进入处理阶段的事务线程担当**leader线程**，随后进入的线程为**follow线程**，后者会释放latch并阻塞等待，直至leader完成并commit

    - flush

        由队列管理，leader会一直读取队列中的事务，直至队列为空或超时（超时保护，防止一直读取），**保证新加入的事务也可以得到处理**，最后向binlog buffer**依次写**这些事务的二进制日志

    - sync/通知follow

        根据`sync_binlog`参数调用fsync()，可以一次性刷盘多个事务

    - commit/通知follow

        根据`opt_binlog_order_commits`，可以按写入顺序调用事务提交，也可以让线程调用`handlerton -> commit`各自提交

4. 提交redo的写

    - binlog组提交完成后，**触发redo日志**的刷盘规则

        > 优化过后，将commit record写入到log buffer即可，因为在第三步中已经确保binlog有记录，这样可以减少fsync()调用次数，提升效率

# 参考
- [理解Mysql中的Buffer pool](https://www.cnblogs.com/wxlevel/p/12995324.html)
- [详解MySQL中的缓冲池](https://blog.csdn.net/weixin_42305622/article/details/113424622)
- [Mysql Buffer Pool](https://blog.csdn.net/qq_27347991/article/details/81052728)

- [MySQL日志系统：redo log、binlog、undo log 区别与作用](https://blog.csdn.net/u010002184/article/details/88526708)

# 重点参考
- [详细分析MySQL事务日志(redo log和undo log)](https://www.cnblogs.com/f-ck-need-u/archive/2018/05/08/9010872.html#auto_id_2)
- [MySQL中常见的几种日志](https://zhuanlan.zhihu.com/p/150105821?from_voters_page=true)

- [Mydql数据库缓存池Buffer Pool 冷热数据分离](https://www.cnblogs.com/maz9666/p/14447334.html)

- [MySQL数据库丢失数据场景分析](http://blog.itpub.net/30109892/viewspace-2062493/)

- [mysql 5.6 binlog组提交实现原理](http://blog.itpub.net/15480802/viewspace-1411356/)
- [深度解析Binlog组提交过程](https://blog.csdn.net/sun_ashe/article/details/104599235)

- [一致性hash算法](https://blog.csdn.net/weixin_39695241/article/details/111641289)
# Redis缓存

> [Redis持久化](https://asea-cch.life/achrives/redis持久化)

当开启持久化时，作为数据库使用。不开启持久化时，作为高效的缓存方案

# **1. 缓存配置**

作为缓存服务器，不加以**限制内存**会出现整台服务器内存被耗光的情况，通过以下思路进行限制保护：
- **配置缓存内存限制和清理策略**
- **关闭持久化**
- 可选项：增加ip绑定、指定客户端连接数量、考虑主从模式

具体配置：
```shell
# 限定redis的最大内存使用量
maxmemory 1536mb

# 指定缓存淘汰算法
maxmemory-policy allkeys-lru

# 配对lru算法配置
maxmemory-samples 5

# 只做缓存服务器，所以关闭持久化
save ""
```

## **1.1 maxmemory**

- =0：表示缓存的数据量没有限制
- \>0：超过该数据时，将触发数据淘汰

设置`maxmemory`的值为物理内存的`3/4或更小`较为合适，牺牲掉一部分内存的原因：
    
> redis复制数据等其他功能也需要使用内存空间，以防缓存数据过大导致redis崩溃

先预测好系统所需要的内存高峰，部署相对应内存的缓存服务器，保证整体系统可用性

基于maxmemory参数，redis有以下两种做法：
1. **接近**maxmemory，通过混合存储冷热交换的方式，采用`近似lru`并结合`eviction pool`，将一些key对应的value存储到磁盘中（key继续留在内存）

    > 这也称为redis的vm内存分配机制

2. **到达**maxmemory，通过缓存置换算法删除键，以达到置换效果

## **1.2 maxmemory-policy（缓存置换算法）**

当redis内存使用量达到了`maxmemory`时，redis会选择设置好的`maxmemory-policy`对老数据进行置换

置换策略有如下6种：
- `noeviction`：即使内存达到上限也不进行置换，所有能引起内存增加的命令都会返回error

- all-key：全量数据，从全部的key中选择删除

    - `allkeys-lru`：lru算法
    - `allkeys-random`：随机算法
    - `allkeys-lfu`：lfu算法

- volatile：部分数据，从设置了ttl的key中选择删除
    > 如果没有设置ttl的键，以下三种策略和`noeviction`策略一样，不会对任何key置换。这就有可能导致无法淘汰出足够多的空间

    - `volatile-lru`：lru算法
    - `volatile-random`：随机算法
    - `volatile-lfu`：lfu算法
    - `volatile-ttl`：ttl最小的key

### **近似LRU算法**

> [真实LRU](https://asea-cch.life/achrives/lru)：以距离上次使用时间作为判断依据，一般指代处于队列头的项

底层结构：`双向链表`

实现思路：出于**节省内存和提升性能**的考虑，Redis的LRU算法**并非完整实现**，采用近似LRU的算法，通过**对少量键进行取样**，从中选择最久未被访问的键进行回收

采样精度（数量）：通过`maxmemory-samples`设置取出数目key

Redis3.0的具体实现：

1. 提供一个待淘汰候选key的`eviction pool`，里面默认有16个key，按照`idle_time`排好序
2. 当内存空间不足时，更新Redis后会从键空间选取`maxmemory-samples`数目key，分别计算它们的idle_time，以此作为依据更新到eviction pool中
    > key在pool不满时，或idle_time大于pool里最小的idle_time时，才会进入pool
3. 从pool中选择空闲时间最大的key淘汰掉

优势（2.8的问题）：2.8并没有将多次选择的结果进行保存，这使得每次新随机选取的key，其idle_time比历史随机选取过的还要新，却被淘汰，导致结果不接近真正的LRU实现

### **算法选择场景**

置换算法没有优劣之分，只有适不适合场景，取决于**应用访问模式**，可以通过`INFO`命令输出cache的命中率情况，进而对置换算法进行调优：

- allkeys-lru：不确定使用哪种策略，或幂次分布（所有key都是最近最经常使用）

- allkeys-random：平等分布（所有key的访问概率差不多）

- volatile-ttl：对数据有足够了解，能够通过expire/ttl为key指定hint，并且缓存对象的ttl值最好有差异

- volatile-lru / volatile-random：单redis实例来同时实现cache和持久化

    未设置过期时间的键进行持久化保存，设置了过期时间的键参与缓存淘汰

## **1.3 置换工作流程**

1. 客户端执行一条写命令，导致数据库需要新增数据
2. Redis检查内存占用，如果内存超过maxmemory，就按照策略删除一些key
3. 删除后，执行写命令，并返回

可以看出，置换的流程属于**被动触发**，一般情况下置换策略会将内存的使用率降低到`maxmemory`以下

如果一次需要使用很多的内存（一次写入很大的数据），那么Redis的真实内存大小可能会超过`maxmemory`限制一段时间

# **2. 使用场景（与memcached区别）**

> 使用缓存的前提：追求`高性能`和`高并发`，外存型数据库性能有瓶颈，访问请求直接打在外存上会导致响应延迟，甚至数据库实例宕机

redis和memcached都是**nosql内存键值**数据库，作为缓存用途时两者经常会被拿来比较

## **2.1 特性差异**

**数据类型：**
- redis：支持5种类型的数据结构
- memcached：只支持字符串

**持久化：**
- redis：提供`rdb`和`aof`持久化方式
- memcached：不支持持久化

**分布式：**
- redis：cluster实现了分布式支持以提高并发量，并提供sentinel满足系统高可用需求
- memcached：不支持分布式，只能**在客户端**使用一致性哈希来实现分布式存储

    > 在存储和查询时都需要在客户端计算一次数据所在的节点

**内存管理机制：**

- redis：

    管理机制：`vm机制（虚拟内存）`

    > 当数据超量时，可以将一些很久没用到的`value`交换（swap）到磁盘中，把key仍然留在内存上

    分配模式：临时申请空间，可能会导致**内存碎片**

    置换机制：在还未到达时，冷热swap；在到达最大内存限定时，使用淘汰机制置换

- memcached：

    管理机制：物理内存

    > 数据直接存到`物理内存`中，一直存在于内存中

    分配模式：**使用内存池预分配管理，可以省去内存分配的时间**，并把内存分割成特定长度的块来存储数据，完全解决了内存碎片的问题，却使得内存利用率不高

    > 例如：块大小为128bytes，只存储100bytes的数据，剩下的28bytes就浪费掉了

    置换机制：直接抹掉前面数据

**I/O模型：**

都采用了`I/O multiplexing`

- redis：`单线程`实现，不存在锁冲突，所以难以利用多核提升整体吞吐量

- memcached：`多线程`实现，主线程监听，worker子线程接受请求，执行读写，可能存在锁冲突

## **2.2 使用场景差异**

memcached：纯kv，数据量大，并发量非常大的业务，使用mc更合适
- 比redis更快的分配速度（预分配，无内存碎片，没有其他工作任务）
- 多线程模型，在锁竞争较小的情况下，可以更好地发挥多核优势

redis：需要运用复合操作函数/更多数据结构支持，分布式高可用的要求下，使用redis更合适

# **3. 缓存引入的新问题**

## **3.1 缓存穿透/缓存击穿/缓存雪崩**

**1. 缓存穿透**

定义：指用户不断发起请求，访问缓存和数据库中**都没有**的数据

问题描述：如果请求不存在的数据都会打到db上，这相当于穿透了缓存层，失去了缓存层的意义

> 利用不存在的key频繁攻击应用，DB可能会因此挂掉

解决方案：

- **从controller层增加参数校验/鉴权校验（必做）**

    如：token，id基础校验

- 从缓存取不到的数据，在数据库中也取不到，则可以将这种情况也**作为缓存的一部分**

    防止用户反复用同一个id暴力攻击，但不建议使用，因为用户完全可以一直使用不同的id进行暴力攻击，这会导致缓存变大

- 布隆过滤器（bloomfilter）

    类似一个hashset，用于快速判断某个元素是否存在于集合中

**2. 缓存击穿**

定义：大并发情况下，用户访问缓存中没有，但数据库却有的**某个单一数据**

问题描述：这种情况一般是key的缓存时间到齐，由于缓存是miss时被动写的（从存储层查询数据），在并发用户特别多的情况下，会触发**多个数据库取数据**的操作，数据库压力将瞬间增大

> 注意，击穿是针对单个key时间失效的，下面讲的雪崩是针对集体时间到达失效的key集

解决方案：

- **设置热点数据永远不过期**

    由修改操作去驱动删除

- 接口限流、熔断与降级
- **加互斥锁**

    即使同时出现多个请求，最终也只有一个请求进行查询

**3. 缓存雪崩**

定义：缓存数据有大批量**同时到达**过期时间

问题描述：在高并发访问的场景下，在某个时间下，有一大批相同过期到达时间的key刚好统一过期，这时候访问压力全部都打到db上，造成db压力剧增

解决方案：
- **缓存数据的过期时间设置为随机，防止同一时间大量数据过期发生**
- **设置热点数据永不过期**
- 如果缓存数据库属于分布式部署，将热点数据**均匀分布**在不同的缓存数据库上

## **3.2 双写一致性**

见[《Mysql和Redis的双写一致性》]()

# 参考
- [Redis只作为缓存，不做持久化的配置](https://www.cnblogs.com/l1pe1/p/7873725.html)

- [什么时候使用redis？什么时候使用memcache？](https://www.cnblogs.com/wangzepu/p/9777662.html)

# 重点参考
- [Redis 缓存过期（maxmemory） 配置/算法 详解](https://www.cnblogs.com/52php/p/6171172.html)
- [Redis中的LRU淘汰策略分析](https://www.cnblogs.com/linxiyue/p/10945216.html)
- [阿里云rds混合存储机制](https://zhuanlan.zhihu.com/p/39918813)
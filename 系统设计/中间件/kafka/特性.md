# Kafka：特性

# **1. 选举（可用性）**

kafka集群部署避免单点问题，分布式势必引入各个broker和topic-partition及其副本的一致性问题，kafka在**两个逻辑维度**添加协调者：

- controller：broker维度

- leader：replica维度

## **1.1 controller**

只有controller在Zookeeper上注册集群功能相应的监听器，其他broker监听`/controller`等少数zk节点，减少羊群效应、脑裂问题

### **1.1.1 选举**

启动选举：

1. /controller

    依赖于zookeeper，每个broker启动后都尝试读取`/controller`节点的brokerid值：

    ```json
    ls /controller
    {"version":1,"brokerid":0,"timestamp":"1529210278988"}
    ```
    - version：目前固定为1
    - brokerid：成功抢占到zk节点的broker其id编号，该broker成为集群controller
    - timestamp：成为controller的时间戳

    broker读取节点共有两种情况，并会在其内存中保存当前控制器的brokerid值（activeContollerId）：

    - brokerid != -1：已有其他broker节点成功竞选为控制器，当前broker放弃竞选zk

    - /controller节点不存在：尝试创建/controller**临时**节点，同一时刻只有一个broker能创建成功

2. /controller_epoch

    zookeeper还有`/controller_epoch`**持久**节点，记录controller发生变更的次数
    
    每个与controller交互的请求都会携带controller_epoch字段，如果请求纪元值小于当前内存纪元值，则表示controller已过期，视为无效请求

退位：关闭controller broker上的相应的资源，如自身的状态机、注销zk相应的监听器

异常下线：/controller临时节点自动删除，**其他broker也能感知到节点变动**，并进行新一轮的zk master选举

### **1.1.2 职责**

- 某个主题的分区数量发生变化时，负责该主题的分区重分配

    原理：

    - zk的`/admin/reassign_partitions`节点注册PartitionReassiginmentHandler，处理**分区重分配的动作**

    - zk的`/brokers/topics/<topic>`节点添加PartitionModificationsHandler，监听**主题中的分区分配变化**

- 某个分区的ISR集合发送变化时，负责通知所有broker更新其元数据

    原理：zk的`/isr_change_notification`节点注册IsrChangeNotificetionHandler

- 某个分区的leader副本出现故障时，负责为该分区选举新的leader副本

    原理：zk的`/admin/preferred-replica-election`节点注册PreferredReplicaElectionHandler


### **1.1.3 线程模型**

竞态条件：controller在读取zk各个节点信息后，初始化controller的上下文信息（ControllerContext），多种异步任务会对ControllorContext进行**读取或更新**

大致可分为3类：
- zk各个节点Watcher可能会触发的任务
- 自身定时任务触发的事件
- 外部调用API触发的事件

方案：采用`单线程基于事件队列模型`实现多线程间的同步问题，避免引入锁降低性能

1. 每个事件都做一层封装
2. 按照事件先后发生顺序，暂存到LinkedBlockingQueue（并发安全的阻塞队列）
3. 最后使用专门的线程（ControllerEventThread）按照FIFO顺序处理各个事件

![controller与其他broker交互的线程模型](https://asea-cch.life/upload/2021/12/controller%E4%B8%8E%E5%85%B6%E4%BB%96broker%E4%BA%A4%E4%BA%92%E7%9A%84%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B-93079b9a85fa42dfa116136207b5c0c6.png)

## **1.2 leader**

思路：按照**AR集合的顺序**顺序查找存活副本，若该副本也在ISR集合中，则被controller选定为分区leader

> AR集合的顺序在分区分配时指定`优先副本`顺序，只要不发生重分配的情况，顺序将保持不变，而ISR集合中的副本顺序可能会改变

当发现ISR集合中没有可用的副本，那么检查`unclean.leader.election.enable`参数是否为true，是的话则允许从非ISR列表（AR列表）中找到第一个存活的副本作为leader

## **1.3 集群有效性最小保证**

不同于ZAB、Raft等协议的过半机制，kafka对消息的确认需要全部副本的确认ack，引入延时问题的同时，集群容忍度获得提升

假设多个机器组成的中间件分布式集群，最多支持2个机器的故障宕机：

- zookeeper集群需要5个节点

- kafka集群只需要3个节点

# **2. 可靠性**

## **2.1 消息传输保障**

消息中间件的消息传输保证有3个层级：

1. at most once：至多一次，消息可能会丢失，但绝对不会重复传输

2. `at least once`：最少一次，消息**绝不会丢失**，但**可能会重复传输**

3. exactly once：恰好一次，消息肯定会被传输一次，且仅传输一次

kafka的层级属于**at least once**，且以下三端对传输保障各有不同的机制：

- 生产者：通过**重试机制**保证消息不丢失

    问题：如果producer发送消息到broker后，遇到网络问题造成通信中断，无法判断broker是否已接到消息

    措施：进行多次重试来确保消息写入kafka，并开启`enable.idempotence=true`以开启生产者客户端的**幂等性功能**

    缺点：
    - producer宕机消息仍会丢失

- broker：通过**多副本机制**确保消息不丢失

    问题：如果单独某个broker接收到消息后宕机，消息将会丢失，出现单点问题

    措施：leader必须让所有数据都在replica确认后，leader才确认这个数据，然后客户端committed response

- consumer：由消费者**处理消息**和**提交消费位移**的顺序决定

    问题：
    - 先处理消息再提交位移，会出现重复消费，对应at least once
    - 先提交位移在处理消息，会出现消息丢失，对应at most once/exactly once

    > 可靠性较高的场景不接受消息丢失，但可以接受重复消息，但需确保消费者的处理具备**幂等性**

    措施：先处理消息（可批处理），再提交处理完毕消息的消费位移

### **结合本地消息表的可靠消息最终一致性方案**

思路：将分布式事务转换为多个本地事务，producer/consumer都通过**异步定时**方式轮询**事务消息表**，保留事件的可靠凭证

- producer：业务线程、timmer、KafkaProducer对应组件

    1. 开启本地事务，保障执行业务成功和消息凭证保存成功的一致性

        ```sql
        begin transaction;
        -- 发起业务操作或处理上游业务
        -- 通知下游的同步操作，转换为凭证消息，保留到生产者消息表（“NEW”）
        end transaction;
        ```
    2. timer异步轮询生产者消息表，开启本地事务，保障发送消息和修改消息状态的一致性

        ```sql
        begin transaction;
        -- 使用以同步方式发送消息到kafka，失败会阻塞重试
        -- 修改消息状态为PROCEEDED
        end transaction;
        ```

- broker：通过**多副本机制**与producer.timer进行可靠性交互

- producer：KafkaConsumer对应组件、timer、业务线程

    1. 启动kafka的IO轮询线程，订阅消费主题后，持续poll(timeout)

    2. 当拉取到消息后，开启本地事务，保证消息成功存入到消息表和提交位移的一致性
    
        > 思路依旧是先处理消息，再提交位移，只是将处理消息的方式通过可靠消息凭证保留，延后异步执行

        ```sql
        begin transaction;
        -- 存入消息到消费者消息表
        -- 提交位移
        end transaction;
        ```

    3. timer异步轮询消费者消息表，开启本地事务，保障成功消费和成功修改消息状态的一致性

        ```sql
        begin transaction;
        -- 执行消费业务逻辑
        -- 修改消费者消息表中，对应kafka消息的消息状态，改为"PROCEEDED"
        end transaction;
        ```


## **2.2 幂等**

producer消息重试，broker通过PID + Sequence机制实现幂等，防止消息重复投递

consumer消费过程宕机，在重启可能会产生重复消费现象，业务端应保障幂等性

# **3. 一致性和延时思考**

Kafka思想：多维度分治

一致性：强一致性，客户端对同一分区的写入，leader副本会等待所有follower副本确认后，才对客户端committed response

延时：
- kafka的集群有效性最少机器保证少，越少的机器进行同步则需要的总延时更少

- 由于`各个ISR副本的数据all committed`，选举时controller可以直接通过AR结合ISR直接指定的方式，减少选举的耗时

脑裂问题：通过zookeeper中/controller结点的抢注，并结合/controller_epoch结点以拒绝旧controller恢复网络通信后可能出现的历史消息

## **主读主写**

主写从读的方式无法分担主的写压力，某种意义上而言，是由于设计缺陷而形成的权宜之计

Kafka通过多个维度切分与分区分配机制，可以将读写压力更灵活地分配到不同的broker结点上，形成更合理的reload分配

# 参考
- [深入理解Kafka-核心设计与实践原理]()
- [kafka11问](https://www.jianshu.com/p/e1af3a703550)

# 重点参考
- [分布式思考：少就是多，多就是少](https://zhuanlan.zhihu.com/p/402990609)
- [Kafka is Database](https://zhuanlan.zhihu.com/p/392645152)